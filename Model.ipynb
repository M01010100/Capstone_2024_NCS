{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.ipynb \n",
    "A proof of use for Homomorphic Encryption. \n",
    "Code was created over several weeks of trial and error, different libraries and implementations. Began with sklearn, and moved to torch. For FHE I ended up on Tenseal but I did have previous iterations with Concrete-ml by Zama AI and Phailiar cryptosystems.\n",
    "Inspired by TenSEAL model\n",
    "\n",
    "# Problems\n",
    "Specifically with the TenSEAL Implementation, which I decided to limit this capstone to along with the CKKS scheme. First, the encrypted data was cast as a CKKS.Vector. The current release for most ML libraries do not have models that can use data in the ''scheme'.vector' form. As a result, some sections had to be manually written instead of predefined functions in the library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import os\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System resources\n",
    "* As this is done in a Jupyter notebook, I'm going to monitor the performance/ usage of the model\n",
    "* This tracking is done using psutil, dtype for Ram, and time.\n",
    "* Laptop is a HP victus - Ryzen 5 8645HS, 16 GB 5600 DDR5, 4050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Memory usage ####\n",
      "Memory usage: 292.91 MB\n",
      "######################\n"
     ]
    }
   ],
   "source": [
    "# prints the memory usage of the current process\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "print(\"#### Memory usage ####\")\n",
    "print_memory_usage()\n",
    "print(\"######################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Preprocessing\n",
    "* using a payment_fraud.csv, given out during a lab for NCS 490, Intro to AI Security, Around 39,000 transactions\n",
    "* payment method is dropped as it is a list of vendors in strings, and balancing\n",
    "* Creating train and test data using sklearn Train_Test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([896, 4])\n",
      "y_train has shape: torch.Size([896, 1])\n",
      "x_test has shape: torch.Size([224, 4])\n",
      "y_test has shape: torch.Size([224, 1])\n",
      "Memory usage: 302.71 MB\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_10384\\1857574243.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=13).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "# The data is a credit card fraud dataset, where the goal is to predict whether a transaction is fraudulent or not\n",
    "# The dataset is highly imbalanced, with only 0.17% of the transactions being fraudulent\n",
    "def Credit_data():\n",
    "    data = pd.read_csv(\"payment_fraud.csv\")\n",
    "    # drop some features\n",
    "    data = data.drop(columns=[\"paymentMethod\"])\n",
    "    # balance data\n",
    "    grouped = data.groupby('label')\n",
    "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=13).reset_index(drop=True))\n",
    "    # extract labels\n",
    "    y = torch.tensor(data[\"label\"].values).float().unsqueeze(1)\n",
    "    data = data.drop(columns=\"label\")\n",
    "    # standardize data\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "def split_train_test(x, y):\n",
    "    # shuffle the data\n",
    "    sklearn.utils.shuffle(x, y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = Credit_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print_memory_usage()\n",
    "print(\"#######################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Encrypted Model\n",
    "* Standard torch logistic regression model.\n",
    "* using print memory to keep track of the model usage of resources  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 1.0242\n",
      "Loss at epoch 2: 0.7431\n",
      "Loss at epoch 3: 0.6005\n",
      "Loss at epoch 4: 0.5368\n",
      "Loss at epoch 5: 0.5026\n",
      "\n",
      "############# Non-Encrypted Training #############\n",
      "Average time per epoch: 0 seconds\n",
      "Non-Encrypted Accuracy: 0.7411\n",
      "Memory usage: 345.75 MB\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "# Deining the Logistic Regression torch NN model.\n",
    "class NE_LR(torch.nn.Module):\n",
    "    # n_features is the number of features in the input data    \n",
    "    def __init__(self, n_features):\n",
    "        super(NE_LR, self).__init__()\n",
    "        # the linear layer is the logistic regression model\n",
    "        # it takes n_features inputs and outputs 1 value\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "    \n",
    "    # pass data through the model and apply sigmoid activation\n",
    "    def forward(self, x):\n",
    "        output = torch.sigmoid(self.lr(x))\n",
    "        return output\n",
    "\n",
    "# Define the model, optimizer, and loss function\n",
    "# Unencrypted training\n",
    "n_features = x_train.shape[1]\n",
    "model = NE_LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "# BCELoss is the loss function used for binary classification\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# train the model for 5 epochs\n",
    "EPOCHS = 5\n",
    "# creating timing list to store the time taken for each epoch\n",
    "times = []\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        start = time()\n",
    "        # set the gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # pass the data through the model\n",
    "        output = model(x)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        # update the weights\n",
    "        optim.step()\n",
    "        end = time()\n",
    "        # loss is printed at each epoch\n",
    "        print(f\"Loss at epoch {e}: {loss.data:.4f}\")\n",
    "        times.append(end - start)\n",
    "        #prints memory usage at epoch 3 - while processing is still occurring.)\n",
    "    return model\n",
    "\n",
    "# Evaluate the model\n",
    "model = train(model, optim, criterion, x_train, y_train)\n",
    "#Calculating the accuracy of the model\n",
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "print(\"\\n############# Non-Encrypted Training #############\")\n",
    "print(f\"Average time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "NE_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Non-Encrypted Accuracy: {NE_accuracy:.4f}\")\n",
    "print_memory_usage()\n",
    "print(\"##################################################\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Encrypted Network\n",
    "* requires defining normally standard functions such as sigmoid, the forward pass, backward, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncryptedLR:\n",
    "    # Encrypted Logistic Regression model    \n",
    "    def __init__(self, torch_lr):\n",
    "        # extract the weights and bias from the torch model\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        # extract the bias from the torch model\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        #initialize the gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    #Forward pass\n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        #Calculates linear combination of input and weight, adds bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        #Applies sigmoid function\n",
    "        return enc_out\n",
    "    \n",
    "    #Backward pass\n",
    "    #Calculates the gradient of the loss w.r.t the weights and bias\n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        #Calculates the difference between the predicted value and the true value\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        #Calculates the gradient of the loss w.r.t the weights\n",
    "        self._delta_b += out_minus_y\n",
    "        #Calculates the gradient of the loss w.r.t the bias\n",
    "        self._count += 1\n",
    "        #Increment the iteration count\n",
    "        \n",
    "    #Update the weights and bias\n",
    "    def update_parameters(self):\n",
    "        # update weights\n",
    "        # Small regularization term to keep the output of the linear layer in the range of the sigmoid\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    #Sigmoid function\n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # this is a degree 3 polynomial approximation of the sigmoid function\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "    #Calculates the accuracy of the model on non-encrypted data\n",
    "        # convert the weights and bias to torch tensors\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        # pass the data through the linear layer\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        # calculate the accuracy\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "    \n",
    "    def encrypt(self, context):\n",
    "    #Encrypts the weights and bias\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "\n",
    "    def decrypt(self):\n",
    "    #Decrypts the weights and bias\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the Encryption\n",
    "* using CKKS encryption, because of using the sigmoid function for the output function. \n",
    "* Supports a wider range of Mathematical operations, Noise management, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Encryption #############\n",
      "Encryption of the training_set took 12 seconds\n",
      "Memory usage: 2286.07 MB\n",
      "######################################\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "# the degree of the polynomial modulus\n",
    "poly_mod_degree = 8192\n",
    "# the bit-length of the modulus chain\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "enc_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "# generate keys\n",
    "enc_training.global_scale = 2 ** 21\n",
    "enc_training.generate_galois_keys()\n",
    "\n",
    "t_start = time()\n",
    "enc_x_train = [ts.ckks_vector(enc_training, x.tolist()) for x in x_train]\n",
    "enc_y_train = [ts.ckks_vector(enc_training, y.tolist()) for y in y_train]\n",
    "t_end = time()\n",
    "print(\"############# Encryption #############\")\n",
    "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")\n",
    "print_memory_usage()\n",
    "print(\"######################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of Datasets\n",
    "* Checking size differential of the encrypted and non-encrypted data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "Size of x_train: 14336 bytes\n",
      "Size of enc_x_train: 392529200 bytes\n",
      "Size of y_train: 3584 bytes\n",
      "Size of enc_y_train: 392569378 bytes\n",
      "Memory usage: 2288.16 MB\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "print(\"############# Data summary #############\")\n",
    "def print_data_sizes(x_train, enc_x_train, y_train, enc_y_train):\n",
    "    print(f\"Size of x_train: {x_train.numpy().nbytes} bytes\")\n",
    "    print(f\"Size of enc_x_train: {sum([len(x.serialize()) for x in enc_x_train])} bytes\")\n",
    "#    print(f\"Size of enc_x_train: {sum([len(x) for x in enc_x_train])} bytes\")\n",
    "    print(f\"Size of y_train: {y_train.numpy().nbytes} bytes\")\n",
    "    print(f\"Size of enc_y_train: {sum([len(y.serialize()) for y in enc_y_train])} bytes\")\n",
    "#    print(f\"Size of enc_y_train: {sum([len(y) for y in enc_y_train])} bytes\")\n",
    "print_data_sizes(x_train, enc_x_train, y_train, enc_y_train)\n",
    "print_memory_usage()\n",
    "print(\"#######################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Encrypted Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch #0 is 0.5669642686843872\n",
      "Accuracy at epoch #1 is 0.7723\n",
      "Accuracy at epoch #2 is 0.7634\n",
      "Accuracy at epoch #3 is 0.7455\n",
      "Accuracy at epoch #4 is 0.7321\n",
      "Memory usage: 2304.91 MB\n",
      "Accuracy at epoch #5 is 0.7366\n",
      "############# Encrypted Training #############\n",
      "\n",
      "Average time per epoch: 48 seconds\n",
      "Accuracy 0.7366\n",
      "Difference between plain and encrypted accuracies: 0.0045\n",
      "Memory usage: 2304.91 MB\n",
      "################################################\n"
     ]
    }
   ],
   "source": [
    "# create the encrypted model\n",
    "ELR = EncryptedLR(NE_LR(n_features))\n",
    "accuracy = ELR.plain_accuracy(x_test, y_test)\n",
    "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "# train the encrypted model\n",
    "times = []\n",
    "for epoch in range(EPOCHS):\n",
    "    ELR.encrypt(enc_training)\n",
    "    \n",
    "    t_start = time()\n",
    "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "        # forward pass\n",
    "        enc_out = ELR.forward(enc_x)\n",
    "        # backward pass\n",
    "        ELR.backward(enc_x, enc_out, enc_y)\n",
    "    ELR.update_parameters()\n",
    "    t_end = time()\n",
    "    times.append(t_end - t_start)\n",
    "    # decrypt the model and calculate the accuracy\n",
    "    ELR.decrypt()\n",
    "    EN_accuracy = ELR.plain_accuracy(x_test, y_test)\n",
    "    print(f\"Accuracy at epoch #{epoch + 1} is {EN_accuracy:.4f}\")\n",
    "    #prints memory usage at epoch 3 - while processing is still occuring.\n",
    "    if(epoch == 3):\n",
    "        print_memory_usage()\n",
    "    #print(f\"Loss at epoch #{epoch + 1} is {(1 - EN_accuracy):.4f}\")\n",
    "\n",
    "print(\"############# Encrypted Training #############\")\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "print(f\"Accuracy {EN_accuracy:.4f}\")\n",
    "diff_accuracy = NE_accuracy - EN_accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy:.4f}\")\n",
    "print_memory_usage()\n",
    "print(\"################################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "* Non-encrypted Accuracy is 0.7411\n",
    "* Encrypted Accuracy is 0.7366\n",
    "* In this situation the encrypted model did better than the non-encrypted version.\n",
    "\n",
    "# Size\n",
    "* Extreme size difference, 14,336 bytes to 392586908 bytes for X_train, although it was done through the use of serializing as nbytes does not work with CKKS.vecors\n",
    "\n",
    "# Time\n",
    "* The Non-encrypted model took less than a second per epoch with the cell needing 0.1 seconds to compute.\n",
    "* Data Encryption took 13.8 seconds to complete\n",
    "* The Encrypted Model took an average of just under 1 minute per epoch (58 seconds), and 4 minutes and 53 seconds to complete.\n",
    "\n",
    "# Resources\n",
    "* Non-encrypted model used 345.75 MB of memory\n",
    "* Encryption used 2.2 Gigabytes of Memory to complete\n",
    "* The Encrypted model used 2.3 Gigabytes of memory as well\n",
    "\n",
    "# Remarks\n",
    "* 27,000 times more bytes needed from 14 KilaBytes to 329 MegaBytes. \n",
    "* 2446 times longer from 0.1 seconds to 4min and 4.6 seconds\n",
    "* While I Plan to continue studying in this field it is good to note, that as of now there is a better version being worked on and developed. SEAL has been unofficially killed by Microsoft as there is no longer a team working on the library, which also means TenSEAL is defunct as well. This model was inspired by one using TenSEAL "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

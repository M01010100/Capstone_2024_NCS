{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.ipynb \n",
    "A proof of use for Homomorphic Encryption. \n",
    "Code was created over several weeks of trial and error, different libraries and implementations. Began with sklearn, moved to torch. For FHE I ended up on Tenseal but I did have previous iterations with Conrete-ml by Zama AI and Phailiar cryptosystems.\n",
    "\n",
    "# Problems\n",
    "Specifically with the TenSEAL Implementation, which I decided to limit this capstone to along with the CKKS scheme. First it was the encrypted data was cast as a CKKS.Vector. The current release for most ML libraries do not have models that can use data in the 'scheme'.vector form. Was forced to write sections which would be predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import os\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System resources\n",
    "* As this is done in a Jupyter notebook, Im going to monitor the performance/ usage of the model\n",
    "* This tracking is done using psutil, dtype for Ram, and time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the memory usage of the current process\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 1275.83 MB\n",
      "############# Data summary #############\n",
      "x_train has shape: torch.Size([896, 4])\n",
      "y_train has shape: torch.Size([896, 1])\n",
      "x_test has shape: torch.Size([224, 4])\n",
      "y_test has shape: torch.Size([224, 1])\n",
      "Memory usage: 1294.18 MB\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matt\\AppData\\Local\\Temp\\ipykernel_26064\\3758387456.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=13).reset_index(drop=True))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "# The data is a credit card fraud dataset, where the goal is to predict whether a transaction is fraudulent or not\n",
    "# The dataset is highly imbalanced, with only 0.17% of the transactions being fraudulent\n",
    "def Credit_data():\n",
    "    data = pd.read_csv(\"payment_fraud.csv\")\n",
    "    # drop some features\n",
    "    data = data.drop(columns=[\"paymentMethod\"])\n",
    "    # balance data\n",
    "    grouped = data.groupby('label')\n",
    "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=13).reset_index(drop=True))\n",
    "    # extract labels\n",
    "    y = torch.tensor(data[\"label\"].values).float().unsqueeze(1)\n",
    "    data = data.drop(columns=\"label\")\n",
    "    # standardize data\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "def split_train_test(x, y):\n",
    "    sklearn.utils.shuffle(x, y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = Credit_data()\n",
    "\n",
    "print(\"############# Data summary #############\")\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")\n",
    "print_memory_usage()\n",
    "print(\"#######################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Encrypted Model\n",
    "* Standard torch logistic regression model.\n",
    "* using print memeory to keep track of the models usage of resources  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 0.7540\n",
      "Loss at epoch 2: 0.6067\n",
      "Loss at epoch 3: 0.5355\n",
      "Loss at epoch 4: 0.4996\n",
      "Loss at epoch 5: 0.4781\n",
      "\n",
      "Average time per epoch: 0 seconds\n",
      "Non-Encrypted Accuracy: 0.7277\n",
      "#######################################\n",
      "Memory usage: 1140.67 MB\n"
     ]
    }
   ],
   "source": [
    "# Deining the Logistic Regression torch NN model.\n",
    "class NE_LR(torch.nn.Module):\n",
    "    # n_features is the number of features in the input data    \n",
    "    def __init__(self, n_features):\n",
    "        super(NE_LR, self).__init__()\n",
    "        # the linear layer is the logistic regression model\n",
    "        # it takes n_features inputs and outputs 1 value\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "    \n",
    "    # pass data through the model and apply sigmoid activation\n",
    "    def forward(self, x):\n",
    "        output = torch.sigmoid(self.lr(x))\n",
    "        return output\n",
    "\n",
    "# Define the model, optimizer and loss function\n",
    "# Unencrypted training\n",
    "n_features = x_train.shape[1]\n",
    "model = NE_LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "# BCELoss is the loss function used for binary classification\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# train the model for 5 epochs\n",
    "EPOCHS = 5\n",
    "# creating timimng list to store the time taken for each epoch\n",
    "times = []\n",
    "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
    "    for e in range(1, epochs + 1):\n",
    "        start = time()\n",
    "        # set the gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # pass the data through the model\n",
    "        output = model(x)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        # update the weights\n",
    "        optim.step()\n",
    "        end = time()\n",
    "        # loss is printed at each epoch\n",
    "        print(f\"Loss at epoch {e}: {loss.data:.4f}\")\n",
    "        times.append(end - start)\n",
    "    return model\n",
    "\n",
    "# Evaluate the model\n",
    "model = train(model, optim, criterion, x_train, y_train)\n",
    "#Calculating the accuracy of the model\n",
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "\n",
    "NE_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Non-Encrypted Accuracy: {NE_accuracy:.4f}\")\n",
    "print(\"#######################################\")\n",
    "print_memory_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Encrypted Network\n",
    "* requires defining normally standard functions such as sigmoid, the forward pass, backward, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncryptedLR:\n",
    "    # Encrypted Logistic Regression model    \n",
    "    def __init__(self, torch_lr):\n",
    "        # extract the weights and bias from the torch model\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        # extract the bias from the torch model\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        #initialize the gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    #Forward pass\n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        #Calculates linear combination of input and weight, adds bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        #Applies sigmoid function\n",
    "        return enc_out\n",
    "    \n",
    "    #Backward pass\n",
    "    #Calculates the gradient of the loss w.r.t the weights and bias\n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        #Calculates the difference between the predicted value and the true value\n",
    "        self._delta_w += enc_x * out_minus_y\n",
    "        #Calculates the gradient of the loss w.r.t the weights\n",
    "        self._delta_b += out_minus_y\n",
    "        #Calculates the gradient of the loss w.r.t the bias\n",
    "        self._count += 1\n",
    "        #Increment the iteration count\n",
    "        \n",
    "    #Update the weights and bias\n",
    "    def update_parameters(self):\n",
    "        if self._count == 0:\n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "        # update weights\n",
    "        # We use a small regularization term to keep the output\n",
    "        # of the linear layer in the range of the sigmoid approximation\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset gradient accumulators and iterations count\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # this is a degree 3 polynomial approximation of the sigmoid function\n",
    "        #keep the output of the linear layer in the range of the sigmoid approximation\n",
    "        return enc_x.polyval([0.5, 0.197, 0, -0.004])\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "    #Calculates the accuracy of the model on non-encrypted data\n",
    "        # convert the weights and bias to torch tensors\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        # pass the data through the linear layer\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        # calculate the accuracy\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "    \n",
    "    def encrypt(self, context):\n",
    "    #Encrypts the weights and bias\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "\n",
    "    def decrypt(self):\n",
    "    #Decrypts the weights and bias\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the Encryption\n",
    "* using CKKS encryption, because of using the sigmoid function for the output function. \n",
    "* Supports wider range of Mathamatical operations, Noise managements, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the training_set took 19 seconds\n",
      "#######################################\n",
      "Memory usage: 1188.57 MB\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "# the degree of the polynomial modulus\n",
    "poly_mod_degree = 8192\n",
    "# the bit-length of the modulus chain\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "# create TenSEALContext\n",
    "enc_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "# generate keys\n",
    "enc_training.global_scale = 2 ** 21\n",
    "enc_training.generate_galois_keys()\n",
    "\n",
    "t_start = time()\n",
    "enc_x_train = [ts.ckks_vector(enc_training, x.tolist()) for x in x_train]\n",
    "enc_y_train = [ts.ckks_vector(enc_training, y.tolist()) for y in y_train]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")\n",
    "print(\"#######################################\")\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Encrypted Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch #0 is 0.4017857015132904\n",
      "Accuracy at epoch #1 is 0.7009\n",
      "Accuracy at epoch #2 is 0.7143\n",
      "Accuracy at epoch #3 is 0.7277\n",
      "Accuracy at epoch #4 is 0.7321\n",
      "Memory usage: 1299.29 MB\n",
      "Accuracy at epoch #5 is 0.5670\n",
      "\n",
      "Average time per epoch: 61 seconds\n",
      "Accuracy 0.5670\n",
      "Difference between plain and encrypted accuracies: 0.1607\n",
      "#######################################\n",
      "Memory usage: 1300.38 MB\n"
     ]
    }
   ],
   "source": [
    "# create the encrypted model\n",
    "ELR = EncryptedLR(NE_LR(n_features))\n",
    "accuracy = ELR.plain_accuracy(x_test, y_test)\n",
    "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "# train the encrypted model\n",
    "times = []\n",
    "for epoch in range(EPOCHS):\n",
    "    ELR.encrypt(enc_training)\n",
    "    \n",
    "    t_start = time()\n",
    "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "        # forward pass\n",
    "        enc_out = ELR.forward(enc_x)\n",
    "        # backward pass\n",
    "        ELR.backward(enc_x, enc_out, enc_y)\n",
    "    ELR.update_parameters()\n",
    "    t_end = time()\n",
    "    times.append(t_end - t_start)\n",
    "    # decrypt the model and calculate the accuracy\n",
    "    ELR.decrypt()\n",
    "    EN_accuracy = ELR.plain_accuracy(x_test, y_test)\n",
    "    print(f\"Accuracy at epoch #{epoch + 1} is {EN_accuracy:.4f}\")\n",
    "    #prints memory usage at epoch 3 - while processing is still occuring.\n",
    "    if(epoch == 3):\n",
    "\n",
    "        print_memory_usage()\n",
    "    #print_memory_usage()\n",
    "    #print(f\"Loss at epoch #{epoch + 1} is {(1 - EN_accuracy):.4f}\")\n",
    "\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / len(times))} seconds\")\n",
    "\n",
    "print(f\"Accuracy {EN_accuracy:.4f}\")\n",
    "\n",
    "diff_accuracy = NE_accuracy - EN_accuracy\n",
    "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy:.4f}\")\n",
    "print(\"#######################################\")\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Data summary #############\n",
      "################ nbytes ################\n",
      "Size of x_train: 14336 bytes\n",
      "Size of enc_x_train: 392574707 bytes\n",
      "Size of y_train: 3584 bytes\n",
      "Size of enc_y_train: 241580658 bytes\n",
      "#######################################\n",
      "Memory usage: 1292.91 MB\n",
      "\n",
      "#######################################\n",
      "################ Pickel ###############\n",
      "Size of x_train: 14737 bytes\n",
      "Size of enc_x_train: 392582771 bytes\n",
      "Size of y_train: 3985 bytes\n",
      "Size of enc_y_train: 241588722 bytes\n",
      "#######################################\n",
      "Memory usage: 1294.40 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"############# Data summary #############\")\n",
    "print(\"################ nbytes ################\")\n",
    "def print_data_sizes(x_train, enc_x_train, y_train, enc_y_train):\n",
    "    print(f\"Size of x_train: {x_train.numpy().nbytes} bytes\")\n",
    "    print(f\"Size of enc_x_train: {sum([len(x.serialize()) for x in enc_x_train])} bytes\")\n",
    "#    print(f\"Size of enc_x_train: {sum([len(x) for x in enc_x_train])} bytes\")\n",
    "    print(f\"Size of y_train: {y_train.numpy().nbytes} bytes\")\n",
    "    print(f\"Size of enc_y_train: {sum([len(y.serialize()) for y in enc_y_train])} bytes\")\n",
    "#    print(f\"Size of enc_y_train: {sum([len(y) for y in enc_y_train])} bytes\")\n",
    "print_data_sizes(x_train, enc_x_train, y_train, enc_y_train)\n",
    "print(\"#######################################\")\n",
    "print_memory_usage()\n",
    "\n",
    "print(\"\\n#######################################\")\n",
    "print(\"################ Pickel ###############\")\n",
    "import pickle\n",
    "\n",
    "def get_pickle_size(obj):\n",
    "    return len(pickle.dumps(obj))\n",
    "\n",
    "def print_data_sizes(x_train, enc_x_train, y_train, enc_y_train):\n",
    "    print(f\"Size of x_train: {get_pickle_size(x_train)} bytes\")\n",
    "    print(f\"Size of enc_x_train: {sum([get_pickle_size(x.serialize()) for x in enc_x_train])} bytes\")\n",
    "    print(f\"Size of y_train: {get_pickle_size(y_train)} bytes\")\n",
    "    print(f\"Size of enc_y_train: {sum([get_pickle_size(y.serialize()) for y in enc_y_train])} bytes\")\n",
    "\n",
    "print_data_sizes(x_train, enc_x_train, y_train, enc_y_train)\n",
    "print(\"#######################################\")\n",
    "print_memory_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
